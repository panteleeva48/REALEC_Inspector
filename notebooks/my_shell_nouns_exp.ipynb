{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "punctuation_marks = punctuation + '»«–…'\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.8\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://wiki.python.su/Документации/BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_info(clusters):\n",
    "    d_sents = {}\n",
    "    for cl in clusters:\n",
    "        units = cl.findAll(\"alignunit\")\n",
    "        for u in units:\n",
    "            sents = u.findAll(\"sent\")\n",
    "            for s in sents:\n",
    "                _id_sent = s['sent_id']\n",
    "                tokens = s.findAll('tok')\n",
    "                sent = ''\n",
    "                l_tokens = []\n",
    "                for t in tokens:\n",
    "                    _id_tok = t['id']\n",
    "                    lemma = t['mate_lemma']\n",
    "                    pos = t['mate_pos']\n",
    "                    token = t.string\n",
    "                    l_tokens.append([_id_tok, lemma, token, pos])\n",
    "                    if token in punctuation_marks:\n",
    "                        sent += token\n",
    "                    else:\n",
    "                        if sent.endswith(\"'\"):\n",
    "                            sent += token\n",
    "                        else:\n",
    "                            sent += ' ' + token\n",
    "                d_sents[_id_sent] = [sent.strip(), l_tokens]\n",
    "    return d_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shell_nouns(y):\n",
    "    shell_nouns = y.europarl_chunk.shellnouns.findAll(\"shellnoun\")\n",
    "    d_shell_nouns = {}\n",
    "    for sn in shell_nouns:\n",
    "        span = sn['span']\n",
    "        value = sn['value']\n",
    "        d_shell_nouns[span] = [value]\n",
    "    return d_shell_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(file):\n",
    "    with open(file, 'r') as file:\n",
    "        f = file.read()\n",
    "    y=BeautifulSoup(f)\n",
    "    clusters = y.europarl_chunk.findAll(\"turn\", lang=\"en\")\n",
    "    d_sents = get_sent_info(clusters)\n",
    "    d_shell_nouns = get_shell_nouns(y)\n",
    "    return d_sents, d_shell_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'annotator1/'\n",
    "xmls = []\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        xmls.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7368a24d6b4447e59c4a378748ebcd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, xml in tqdm(enumerate(xmls)):\n",
    "    d_sents, d_shell_nouns = get_info(xml)\n",
    "    for se in d_sents:\n",
    "        whole_sent = d_sents[se][0] # предложение целиком\n",
    "        tokens = d_sents[se][1]\n",
    "        for t in tokens:\n",
    "            if t[0] in d_shell_nouns.keys():\n",
    "                d_shell_nouns[t[0]].append(t[2]) # присоединяем токен\n",
    "                d_shell_nouns[t[0]].append(t[1]) # присоединяем лемму\n",
    "                d_shell_nouns[t[0]].append(se) # присоединяем id предложения\n",
    "                d_shell_nouns[t[0]].append(d_sents[se][0]) # присоединяем предложение\n",
    "                all_info.append([xml, t[0]] + d_shell_nouns[t[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotator1/ep-01-02-28.xml',\n",
       " 't_455',\n",
       " 'true',\n",
       " 'view',\n",
       " 'view',\n",
       " 's_14',\n",
       " 'Would he share with me the view that, if the Council took more interest in his reforms, it would help their speedy and thorough implementation to achieve the end that we all want, which is the most professional and effective European civil service.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import ParserUDpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame(data={'Id': [], 'Form': [], 'Lemma': [],\n",
    "                         'UPosTag': [], 'XPosTag': [], 'Feats': [],\n",
    "                         'Head': [], 'DepRel': [], 'Deps': [],\n",
    "                         'Misc': [], 'Tag': [], 'Sent': []})\n",
    "i = 0\n",
    "for inf in all_info:\n",
    "    try:\n",
    "        token = inf[3]\n",
    "        sent = inf[6]\n",
    "        value = inf[2]\n",
    "        parser = ParserUDpipe(sent)\n",
    "        df = parser.conllu2df()\n",
    "        tags = ['context'] * len(df)\n",
    "        tags[list(df['Form']).index(token)] = value\n",
    "        df['Tag'] = tags\n",
    "        df['Sent'] = [i] * len(df)\n",
    "        res = pd.concat([res, df])\n",
    "    except:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.drop(['Id', 'XPosTag', 'Feats', 'Head', 'Deps', 'Misc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_context(lemmas, window):\n",
    "    return list(lemmas)[window:] + ['END'] * window\n",
    "def get_left_context(lemmas, window):\n",
    "    return ['START'] * window + list(lemmas)[:-window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_lemma = []\n",
    "next_next_lemma = []\n",
    "next_next_next_lemma = []\n",
    "next_next_next_next_lemma = []\n",
    "for s in set(res['Sent']):\n",
    "    lemmas = res[res['Sent'] == s]['Lemma']\n",
    "    next_lemma += get_right_context(lemmas, 1)\n",
    "    next_next_lemma += get_right_context(lemmas, 2)\n",
    "    next_next_next_lemma += get_right_context(lemmas, 3)\n",
    "    next_next_next_next_lemma += get_right_context(lemmas, 4)\n",
    "res['next_lemma'] = next_lemma\n",
    "res['next_next_lemma'] = next_next_lemma\n",
    "res['next_next_next_lemma'] = next_next_next_lemma\n",
    "res['next_next_next_next_lemma'] = next_next_next_next_lemma\n",
    "\n",
    "next_pos = []\n",
    "next_next_pos = []\n",
    "next_next_next_pos = []\n",
    "next_next_next_next_pos = []\n",
    "for s in set(res['Sent']):\n",
    "    poss = res[res['Sent'] == s]['UPosTag']\n",
    "    next_pos += get_right_context(poss, 1)\n",
    "    next_next_pos += get_right_context(poss, 2)\n",
    "    next_next_next_pos += get_right_context(poss, 3)\n",
    "    next_next_next_next_pos += get_right_context(poss, 4)\n",
    "res['next_pos'] = next_pos\n",
    "res['next_next_pos'] = next_next_pos\n",
    "res['next_next_next_pos'] = next_next_next_pos\n",
    "res['next_next_next_next_pos'] = next_next_next_next_pos\n",
    "\n",
    "next_rel = []\n",
    "next_next_rel = []\n",
    "next_next_next_rel = []\n",
    "next_next_next_next_rel = []\n",
    "for s in set(res['Sent']):\n",
    "    rels = res[res['Sent'] == s]['DepRel']\n",
    "    next_rel += get_right_context(rels, 1)\n",
    "    next_next_rel += get_right_context(rels, 2)\n",
    "    next_next_next_rel += get_right_context(rels, 3)\n",
    "    next_next_next_next_rel += get_right_context(rels, 4)\n",
    "res['next_rel'] = next_rel\n",
    "res['next_next_rel'] = next_next_rel\n",
    "res['next_next_next_rel'] = next_next_next_rel\n",
    "res['next_next_next_next_rel'] = next_next_next_next_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lemma = []\n",
    "pre_pre_lemma = []\n",
    "pre_pre_pre_lemma = []\n",
    "pre_pre_pre_pre_lemma = []\n",
    "for s in set(res['Sent']):\n",
    "    lemmas = res[res['Sent'] == s]['Lemma']\n",
    "    pre_lemma += get_left_context(lemmas, 1)\n",
    "    pre_pre_lemma += get_left_context(lemmas, 2)\n",
    "    pre_pre_pre_lemma += get_left_context(lemmas, 3)\n",
    "    pre_pre_pre_pre_lemma += get_left_context(lemmas, 4)\n",
    "res['pre_lemma'] = pre_lemma\n",
    "res['pre_pre_lemma'] = pre_pre_lemma\n",
    "res['pre_pre_pre_lemma'] = pre_pre_pre_lemma\n",
    "res['pre_pre_pre_pre_lemma'] = pre_pre_pre_pre_lemma\n",
    "\n",
    "pre_pos = []\n",
    "pre_pre_pos = []\n",
    "pre_pre_pre_pos = []\n",
    "pre_pre_pre_pre_pos = []\n",
    "for s in set(res['Sent']):\n",
    "    poss = res[res['Sent'] == s]['UPosTag']\n",
    "    pre_pos += get_left_context(poss, 1)\n",
    "    pre_pre_pos += get_left_context(poss, 2)\n",
    "    pre_pre_pre_pos += get_left_context(poss, 3)\n",
    "    pre_pre_pre_pre_pos += get_left_context(poss, 4)\n",
    "res['pre_pos'] = pre_pos\n",
    "res['pre_pre_pos'] = pre_pre_pos\n",
    "res['pre_pre_pre_pos'] = pre_pre_pre_pos\n",
    "res['pre_pre_pre_pre_pos'] = pre_pre_pre_pre_pos\n",
    "\n",
    "pre_rel = []\n",
    "pre_pre_rel = []\n",
    "pre_pre_pre_rel = []\n",
    "pre_pre_pre_pre_rel = []\n",
    "for s in set(res['Sent']):\n",
    "    rels = res[res['Sent'] == s]['DepRel']\n",
    "    pre_rel += get_left_context(rels, 1)\n",
    "    pre_pre_rel += get_left_context(rels, 2)\n",
    "    pre_pre_pre_rel += get_left_context(rels, 3)\n",
    "    pre_pre_pre_pre_rel += get_left_context(rels, 4)\n",
    "res['pre_rel'] = pre_rel\n",
    "res['pre_pre_rel'] = pre_pre_rel\n",
    "res['pre_pre_pre_rel'] = pre_pre_pre_rel\n",
    "res['pre_pre_pre_pre_rel'] = pre_pre_pre_pre_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "that = []\n",
    "for s in set(res['Sent']):\n",
    "    lemmas = list(res[res['Sent'] == s]['Lemma'])\n",
    "    if 'that' in lemmas:\n",
    "        that += [1] * len(lemmas)\n",
    "    else:\n",
    "        that += [0] * len(lemmas)\n",
    "res['that'] = that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = res[~(res['Tag'] == 'context')]\n",
    "df = df[~(df['Tag'] == 'undefined')]\n",
    "df = df[~(df['Tag'] == 'unclear')]\n",
    "df['Tag'] = df['Tag'].map({'true': 1, 'false': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>UPosTag</th>\n",
       "      <th>DepRel</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sent</th>\n",
       "      <th>next_lemma</th>\n",
       "      <th>next_next_lemma</th>\n",
       "      <th>next_next_next_lemma</th>\n",
       "      <th>next_next_next_next_lemma</th>\n",
       "      <th>...</th>\n",
       "      <th>pre_pre_pre_pre_lemma</th>\n",
       "      <th>pre_pos</th>\n",
       "      <th>pre_pre_pos</th>\n",
       "      <th>pre_pre_pre_pos</th>\n",
       "      <th>pre_pre_pre_pre_pos</th>\n",
       "      <th>pre_rel</th>\n",
       "      <th>pre_pre_rel</th>\n",
       "      <th>pre_pre_pre_rel</th>\n",
       "      <th>pre_pre_pre_pre_rel</th>\n",
       "      <th>that</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>that</td>\n",
       "      <td>,</td>\n",
       "      <td>if</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>share</td>\n",
       "      <td>DET</td>\n",
       "      <td>PRON</td>\n",
       "      <td>ADP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>det</td>\n",
       "      <td>obl</td>\n",
       "      <td>case</td>\n",
       "      <td>root</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>end</td>\n",
       "      <td>end</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>that</td>\n",
       "      <td>we</td>\n",
       "      <td>all</td>\n",
       "      <td>want</td>\n",
       "      <td>...</td>\n",
       "      <td>implementation</td>\n",
       "      <td>DET</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PART</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>det</td>\n",
       "      <td>advcl</td>\n",
       "      <td>mark</td>\n",
       "      <td>conj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>proposals</td>\n",
       "      <td>proposal</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>you</td>\n",
       "      <td>have</td>\n",
       "      <td>make</td>\n",
       "      <td>,</td>\n",
       "      <td>...</td>\n",
       "      <td>you</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PRON</td>\n",
       "      <td>amod</td>\n",
       "      <td>det</td>\n",
       "      <td>case</td>\n",
       "      <td>obj</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>question</td>\n",
       "      <td>question</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>,</td>\n",
       "      <td>lately</td>\n",
       "      <td>many</td>\n",
       "      <td>commission</td>\n",
       "      <td>...</td>\n",
       "      <td>on</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>amod</td>\n",
       "      <td>det</td>\n",
       "      <td>case</td>\n",
       "      <td>case</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>decision</td>\n",
       "      <td>decision</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>make</td>\n",
       "      <td>because</td>\n",
       "      <td>of</td>\n",
       "      <td>what</td>\n",
       "      <td>...</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADV</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PART</td>\n",
       "      <td>case</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>mark</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Form     Lemma UPosTag DepRel  Tag  Sent next_lemma next_next_lemma  \\\n",
       "6        view      view    NOUN    obj    1   0.0       that               ,   \n",
       "30        end       end    NOUN    obj    1   1.0       that              we   \n",
       "14  proposals  proposal    NOUN    obl    0   2.0        you            have   \n",
       "5    question  question    NOUN    obl    0   3.0          ,          lately   \n",
       "17   decision  decision    NOUN    obl    0   4.0       make         because   \n",
       "\n",
       "   next_next_next_lemma next_next_next_next_lemma  ... pre_pre_pre_pre_lemma  \\\n",
       "6                    if                       the  ...                 share   \n",
       "30                  all                      want  ...        implementation   \n",
       "14                 make                         ,  ...                   you   \n",
       "5                  many                commission  ...                    on   \n",
       "17                   of                      what  ...                    to   \n",
       "\n",
       "   pre_pos pre_pre_pos pre_pre_pre_pos pre_pre_pre_pre_pos pre_rel  \\\n",
       "6      DET        PRON             ADP                VERB     det   \n",
       "30     DET        VERB            PART                NOUN     det   \n",
       "14     ADJ         DET             ADP                PRON    amod   \n",
       "5      ADJ         DET             ADP                 ADP    amod   \n",
       "17     ADP         ADV            VERB                PART    case   \n",
       "\n",
       "   pre_pre_rel pre_pre_pre_rel pre_pre_pre_pre_rel that  \n",
       "6          obl            case                root    1  \n",
       "30       advcl            mark                conj    1  \n",
       "14         det            case                 obj    0  \n",
       "5          det            case                case    0  \n",
       "17      advmod           xcomp                mark    0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.564955\n",
       "1    0.435045\n",
       "Name: Tag, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts(normalize=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "SEED = 55\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ['Tag', 'Sent']]\n",
    "X_train = df[cols]\n",
    "y_train = df['Tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df_train, df_test, cat_cols, num_cols=None, word_cols=None, embeddings=None):\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(pd.concat([df_train[cat_cols], df_test[cat_cols]]))\n",
    "    \n",
    "    X_train = encoder.transform(df_train[cat_cols])\n",
    "    X_test = encoder.transform(df_test[cat_cols])\n",
    "        \n",
    "    if num_cols is not None:\n",
    "        X_train = sp.hstack(\n",
    "            [\n",
    "                X_train,\n",
    "                np.hstack([df_train[col].values.reshape(-1, 1) for col in num_cols])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        X_test = sp.hstack(\n",
    "            [\n",
    "                X_test,\n",
    "                np.hstack([df_test[col].values.reshape(-1, 1) for col in num_cols])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    if embeddings is not None and word_cols is not None:\n",
    "        X_train = sp.hstack(\n",
    "            [\n",
    "                X_train,\n",
    "                np.hstack([embeddings.transform(df_train[col].values) for col in word_cols])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        X_test = sp.hstack(\n",
    "            [\n",
    "                X_test,\n",
    "                np.hstack([embeddings.transform(df_test[col].values) for col in word_cols])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on REALEC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('test.xlsx', names=['sent', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I believe, that when young people listen their...</td>\n",
       "      <td>notDON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In conclusion, we can see that despite minor c...</td>\n",
       "      <td>notDON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It would be unfair not to mention that nowaday...</td>\n",
       "      <td>notDON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To sum up, I'd like to say that it is a good i...</td>\n",
       "      <td>DON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finaly, in can be noticed that despite the fac...</td>\n",
       "      <td>DON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent     Tag\n",
       "0  I believe, that when young people listen their...  notDON\n",
       "1  In conclusion, we can see that despite minor c...  notDON\n",
       "2  It would be unfair not to mention that nowaday...  notDON\n",
       "3  To sum up, I'd like to say that it is a good i...     DON\n",
       "4  Finaly, in can be noticed that despite the fac...     DON"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import ParserUDpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = pd.DataFrame(data={'Id': [], 'Form': [], 'Lemma': [],\n",
    "                         'UPosTag': [], 'XPosTag': [], 'Feats': [],\n",
    "                         'Head': [], 'DepRel': [], 'Deps': [],\n",
    "                         'Misc': [], 'Sent': []})\n",
    "i = 0\n",
    "for sent in list(test['sent']):\n",
    "    parser = ParserUDpipe(sent)\n",
    "    df = parser.conllu2df()\n",
    "    df['Sent'] = [i] * len(df)\n",
    "    res_test = pd.concat([res_test, df])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test = res_test.drop(['Id', 'XPosTag', 'Feats', 'Head', 'Deps', 'Misc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>UPosTag</th>\n",
       "      <th>DepRel</th>\n",
       "      <th>Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>believe</td>\n",
       "      <td>believe</td>\n",
       "      <td>VERB</td>\n",
       "      <td>root</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>mark</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>mark</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Form    Lemma UPosTag DepRel  Sent\n",
       "0        I        I    PRON  nsubj   0.0\n",
       "1  believe  believe    VERB   root   0.0\n",
       "2        ,        ,   PUNCT  punct   0.0\n",
       "3     that     that   SCONJ   mark   0.0\n",
       "4     when     when   SCONJ   mark   0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"dons\": [\n",
    "        \"thing\", \"fact\", \"point\", \"argument\", \"result\", \"dispute\",\n",
    "        \"problem\", \"factor\", \"approach\", \"view\", \"feeling\", \"process\",\n",
    "        \"theme\", \"attempt\", \"controversy\", \"statement\", \"task\", \"issue\",\n",
    "        \"dream\", \"matter\", \"situation\", \"need\", \"reason\", \"solution\",\n",
    "        \"possibility\", \"change\", \"debate\", \"sense\", \"method\", \"theory\",\n",
    "        \"finding\", \"question\", \"idea\", \"concept\", \"opinion\", \"ideas\", \"things\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n",
      "71.0\n"
     ]
    }
   ],
   "source": [
    "candidates = []\n",
    "for s in set(res_test['Sent']):\n",
    "    ind = False\n",
    "    lemmas = list(res_test[res_test['Sent'] == s]['Lemma'])\n",
    "    for l in lemmas:\n",
    "        for don in d['dons']:\n",
    "            try:\n",
    "                ind = lemmas.index(don)\n",
    "            except:\n",
    "                continue\n",
    "    cands = [0] * len(lemmas)\n",
    "    if ind:\n",
    "        cands[ind] = list(test.Tag)[int(s)]\n",
    "    else:\n",
    "        print(s)\n",
    "    candidates += cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test['Tag'] = candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>UPosTag</th>\n",
       "      <th>DepRel</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>believe</td>\n",
       "      <td>believe</td>\n",
       "      <td>VERB</td>\n",
       "      <td>root</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>mark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>mark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Form    Lemma UPosTag DepRel  Sent Tag\n",
       "0        I        I    PRON  nsubj   0.0   0\n",
       "1  believe  believe    VERB   root   0.0   0\n",
       "2        ,        ,   PUNCT  punct   0.0   0\n",
       "3     that     that   SCONJ   mark   0.0   0\n",
       "4     when     when   SCONJ   mark   0.0   0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_lemma = []\n",
    "next_next_lemma = []\n",
    "next_next_next_lemma = []\n",
    "next_next_next_next_lemma = []\n",
    "for s in set(res_test['Sent']):\n",
    "    lemmas = res_test[res_test['Sent'] == s]['Lemma']\n",
    "    next_lemma += get_right_context(lemmas, 1)\n",
    "    next_next_lemma += get_right_context(lemmas, 2)\n",
    "    next_next_next_lemma += get_right_context(lemmas, 3)\n",
    "    next_next_next_next_lemma += get_right_context(lemmas, 4)\n",
    "res_test['next_lemma'] = next_lemma\n",
    "res_test['next_next_lemma'] = next_next_lemma\n",
    "res_test['next_next_next_lemma'] = next_next_next_lemma\n",
    "res_test['next_next_next_next_lemma'] = next_next_next_next_lemma\n",
    "\n",
    "next_pos = []\n",
    "next_next_pos = []\n",
    "next_next_next_pos = []\n",
    "next_next_next_next_pos = []\n",
    "for s in set(res_test['Sent']):\n",
    "    poss = res_test[res_test['Sent'] == s]['UPosTag']\n",
    "    next_pos += get_right_context(poss, 1)\n",
    "    next_next_pos += get_right_context(poss, 2)\n",
    "    next_next_next_pos += get_right_context(poss, 3)\n",
    "    next_next_next_next_pos += get_right_context(poss, 4)\n",
    "res_test['next_pos'] = next_pos\n",
    "res_test['next_next_pos'] = next_next_pos\n",
    "res_test['next_next_next_pos'] = next_next_next_pos\n",
    "res_test['next_next_next_next_pos'] = next_next_next_next_pos\n",
    "\n",
    "next_rel = []\n",
    "next_next_rel = []\n",
    "next_next_next_rel = []\n",
    "next_next_next_next_rel = []\n",
    "for s in set(res_test['Sent']):\n",
    "    rels = res_test[res_test['Sent'] == s]['DepRel']\n",
    "    next_rel += get_right_context(rels, 1)\n",
    "    next_next_rel += get_right_context(rels, 2)\n",
    "    next_next_next_rel += get_right_context(rels, 3)\n",
    "    next_next_next_next_rel += get_right_context(rels, 4)\n",
    "res_test['next_rel'] = next_rel\n",
    "res_test['next_next_rel'] = next_next_rel\n",
    "res_test['next_next_next_rel'] = next_next_next_rel\n",
    "res_test['next_next_next_next_rel'] = next_next_next_next_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_lemma = []\n",
    "pre_pre_lemma = []\n",
    "pre_pre_pre_lemma = []\n",
    "pre_pre_pre_pre_lemma = []\n",
    "for s in set(res_test['Sent']):\n",
    "    lemmas = res_test[res_test['Sent'] == s]['Lemma']\n",
    "    pre_lemma += get_left_context(lemmas, 1)\n",
    "    pre_pre_lemma += get_left_context(lemmas, 2)\n",
    "    pre_pre_pre_lemma += get_left_context(lemmas, 3)\n",
    "    pre_pre_pre_pre_lemma += get_left_context(lemmas, 4)\n",
    "res_test['pre_lemma'] = pre_lemma\n",
    "res_test['pre_pre_lemma'] = pre_pre_lemma\n",
    "res_test['pre_pre_pre_lemma'] = pre_pre_pre_lemma\n",
    "res_test['pre_pre_pre_pre_lemma'] = pre_pre_pre_pre_lemma\n",
    "\n",
    "pre_pos = []\n",
    "pre_pre_pos = []\n",
    "pre_pre_pre_pos = []\n",
    "pre_pre_pre_pre_pos = []\n",
    "for s in set(res_test['Sent']):\n",
    "    poss = res_test[res_test['Sent'] == s]['UPosTag']\n",
    "    pre_pos += get_left_context(poss, 1)\n",
    "    pre_pre_pos += get_left_context(poss, 2)\n",
    "    pre_pre_pre_pos += get_left_context(poss, 3)\n",
    "    pre_pre_pre_pre_pos += get_left_context(poss, 4)\n",
    "res_test['pre_pos'] = pre_pos\n",
    "res_test['pre_pre_pos'] = pre_pre_pos\n",
    "res_test['pre_pre_pre_pos'] = pre_pre_pre_pos\n",
    "res_test['pre_pre_pre_pre_pos'] = pre_pre_pre_pre_pos\n",
    "\n",
    "pre_rel = []\n",
    "pre_pre_rel = []\n",
    "pre_pre_pre_rel = []\n",
    "pre_pre_pre_pre_rel = []\n",
    "for s in set(res_test['Sent']):\n",
    "    rels = res_test[res_test['Sent'] == s]['DepRel']\n",
    "    pre_rel += get_left_context(rels, 1)\n",
    "    pre_pre_rel += get_left_context(rels, 2)\n",
    "    pre_pre_pre_rel += get_left_context(rels, 3)\n",
    "    pre_pre_pre_pre_rel += get_left_context(rels, 4)\n",
    "res_test['pre_rel'] = pre_rel\n",
    "res_test['pre_pre_rel'] = pre_pre_rel\n",
    "res_test['pre_pre_pre_rel'] = pre_pre_pre_rel\n",
    "res_test['pre_pre_pre_pre_rel'] = pre_pre_pre_pre_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "that = []\n",
    "for s in set(res_test['Sent']):\n",
    "    lemmas = list(res_test[res_test['Sent'] == s]['Lemma'])\n",
    "    if 'that' in lemmas:\n",
    "        that += [1] * len(lemmas)\n",
    "    else:\n",
    "        that += [0] * len(lemmas)\n",
    "res_test['that'] = that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = res_test[~(res_test['Tag'] == 0)]\n",
    "df_test['Tag'] = df_test['Tag'].map({'DON': 1, 'notDON': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Form</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>UPosTag</th>\n",
       "      <th>DepRel</th>\n",
       "      <th>Sent</th>\n",
       "      <th>Tag</th>\n",
       "      <th>next_lemma</th>\n",
       "      <th>next_next_lemma</th>\n",
       "      <th>next_next_next_lemma</th>\n",
       "      <th>next_next_next_next_lemma</th>\n",
       "      <th>...</th>\n",
       "      <th>pre_pre_pre_pre_lemma</th>\n",
       "      <th>pre_pos</th>\n",
       "      <th>pre_pre_pos</th>\n",
       "      <th>pre_pre_pre_pos</th>\n",
       "      <th>pre_pre_pre_pre_pos</th>\n",
       "      <th>pre_rel</th>\n",
       "      <th>pre_pre_rel</th>\n",
       "      <th>pre_pre_pre_rel</th>\n",
       "      <th>pre_pre_pre_pre_rel</th>\n",
       "      <th>that</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>things</td>\n",
       "      <td>thing</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>END</td>\n",
       "      <td>...</td>\n",
       "      <td>world</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>amod</td>\n",
       "      <td>case</td>\n",
       "      <td>advmod</td>\n",
       "      <td>obj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>changes</td>\n",
       "      <td>change</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>different</td>\n",
       "      <td>region</td>\n",
       "      <td>,</td>\n",
       "      <td>...</td>\n",
       "      <td>see</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>amod</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>mark</td>\n",
       "      <td>root</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>process</td>\n",
       "      <td>process</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>nurturing</td>\n",
       "      <td>child</td>\n",
       "      <td>and</td>\n",
       "      <td>...</td>\n",
       "      <td>mention</td>\n",
       "      <td>DET</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PRON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>det</td>\n",
       "      <td>acl:relcl</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>obl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>idea</td>\n",
       "      <td>idea</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>start</td>\n",
       "      <td>learn</td>\n",
       "      <td>foreign</td>\n",
       "      <td>...</td>\n",
       "      <td>it</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>AUX</td>\n",
       "      <td>PRON</td>\n",
       "      <td>amod</td>\n",
       "      <td>det</td>\n",
       "      <td>cop</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>situations</td>\n",
       "      <td>situation</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>future</td>\n",
       "      <td>.</td>\n",
       "      <td>END</td>\n",
       "      <td>...</td>\n",
       "      <td>will</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>VERB</td>\n",
       "      <td>AUX</td>\n",
       "      <td>amod</td>\n",
       "      <td>det</td>\n",
       "      <td>advcl</td>\n",
       "      <td>aux</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Form      Lemma UPosTag DepRel  Sent  Tag next_lemma  \\\n",
       "27      things      thing    NOUN    obl   0.0    0          .   \n",
       "9      changes     change    NOUN    obj   1.0    0         in   \n",
       "10     process    process    NOUN    obj   2.0    0         of   \n",
       "14        idea       idea    NOUN  ccomp   3.0    1         to   \n",
       "24  situations  situation    NOUN    obj   4.0    1         in   \n",
       "\n",
       "   next_next_lemma next_next_next_lemma next_next_next_next_lemma  ...  \\\n",
       "27             END                  END                       END  ...   \n",
       "9        different               region                         ,  ...   \n",
       "10       nurturing                child                       and  ...   \n",
       "14           start                learn                   foreign  ...   \n",
       "24          future                    .                       END  ...   \n",
       "\n",
       "   pre_pre_pre_pre_lemma pre_pos pre_pre_pos pre_pre_pre_pos  \\\n",
       "27                 world     ADJ         ADP             ADV   \n",
       "9                    see     ADJ        VERB           SCONJ   \n",
       "10               mention     DET        VERB            PRON   \n",
       "14                    it     ADJ         DET             AUX   \n",
       "24                  will     ADJ         DET            VERB   \n",
       "\n",
       "   pre_pre_pre_pre_pos pre_rel pre_pre_rel pre_pre_pre_rel  \\\n",
       "27                NOUN    amod        case          advmod   \n",
       "9                 VERB    amod       ccomp            mark   \n",
       "10                NOUN     det   acl:relcl           nsubj   \n",
       "14                PRON    amod         det             cop   \n",
       "24                 AUX    amod         det           advcl   \n",
       "\n",
       "   pre_pre_pre_pre_rel that  \n",
       "27                 obj    1  \n",
       "9                 root    1  \n",
       "10                 obl    1  \n",
       "14               nsubj    1  \n",
       "24                 aux    1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 31)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_test.columns if col not in ['Tag', 'Sent']]\n",
    "X_test = df_test[cols]\n",
    "y_test = df_test['Tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = build_dataset(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    cat_cols=list(X_train.columns)[:-1],\n",
    "    num_cols = ['that']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8019802  0.69       0.78787879 0.68686869 0.70707071 0.83838384\n",
      " 0.64646465 0.70707071 0.75757576 0.81818182]\n",
      "0.7441475147514751\n",
      "CPU times: user 132 ms, sys: 4.91 ms, total: 137 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(random_state=SEED), X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1.0, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8019802  0.69       0.78787879 0.68686869 0.70707071 0.83838384\n",
      " 0.64646465 0.70707071 0.75757576 0.81818182]\n",
      "0.7441475147514751\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(random_state=SEED, C=1.0, penalty='l2'), X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=SEED, C=1.0, penalty='l2').fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726890756302521"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5630252100840336"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "_X_train = X_train.toarray()\n",
    "_X_test = X_test.toarray()\n",
    "model = GaussianNB().fit(_X_train, y_train)\n",
    "preds = model.predict(_X_test)\n",
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42436974789915966"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=SEED).fit(_X_train, y_train)\n",
    "preds = model.predict(_X_test)\n",
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7773109243697479"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel=\"linear\", C=0.025, class_weight='balanced', decision_function_shape='ovo', random_state=SEED).fit(_X_train, y_train)\n",
    "preds = model.predict(_X_test)\n",
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.75        95\n",
      "           1       0.86      0.75      0.80       143\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       238\n",
      "   macro avg       0.77      0.78      0.77       238\n",
      "weighted avg       0.79      0.78      0.78       238\n",
      "\n",
      "[[ 78  17]\n",
      " [ 36 107]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000],'gamma':[1, 0.1, 0.001, 0.0001], 'kernel':['linear','rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid,  cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.001, 0.0001], 'kernel': ['linear', 'rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=10, gamma=0.1, kernel='rbf', random_state=SEED).fit(_X_train, y_train)\n",
    "preds = model.predict(_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6764705882352942"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.89      0.69        95\n",
      "           1       0.88      0.53      0.66       143\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       238\n",
      "   macro avg       0.72      0.71      0.68       238\n",
      "weighted avg       0.75      0.68      0.67       238\n",
      "\n",
      "[[85 10]\n",
      " [67 76]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predic))\n",
    "print(confusion_matrix(y_test, predic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176470588235294"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=5, random_state=SEED).fit(_X_train, y_train)\n",
    "preds = model.predict(_X_test)\n",
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7016806722689075"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "model = AdaBoostClassifier().fit(_X_train, y_train)\n",
    "preds = model.predict(_X_test)\n",
    "metrics.accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# На выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/irene/Desktop/Диплом/code/result_criteria/result_criteria.csv', 'r') as file:\n",
    "    f = file.read()\n",
    "paths = ['/Users/irene/Desktop/Диплом/new_data/'+x+'.txt' for x in f.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "paths = [re.sub(';.+', '', x)+'.txt' for x in paths[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/irene/Desktop/Диплом/new_data/1.txt'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_data_for_model(sent_text, X_train):\n",
    "    try:\n",
    "        res_test = pd.DataFrame(data={'Id': [], 'Form': [], 'Lemma': [],\n",
    "                                      'UPosTag': [], 'XPosTag': [], 'Feats': [],\n",
    "                                      'Head': [], 'DepRel': [], 'Deps': [],\n",
    "                                      'Misc': [], 'Sent': []})\n",
    "        i = 0\n",
    "        for sent in list(sent_text):\n",
    "            parser = ParserUDpipe(sent)\n",
    "            df = parser.conllu2df()\n",
    "            df['Sent'] = [i] * len(df)\n",
    "            res_test = pd.concat([res_test, df])\n",
    "            i += 1\n",
    "        res_test = res_test.drop(['Id', 'XPosTag', 'Feats', 'Head', 'Deps', 'Misc'], axis=1)\n",
    "        d = {\n",
    "        \"dons\": [\n",
    "            \"thing\", \"fact\", \"point\", \"argument\", \"result\", \"dispute\",\n",
    "            \"problem\", \"factor\", \"approach\", \"view\", \"feeling\", \"process\",\n",
    "            \"theme\", \"attempt\", \"controversy\", \"statement\", \"task\", \"issue\",\n",
    "            \"dream\", \"matter\", \"situation\", \"need\", \"reason\", \"solution\",\n",
    "            \"possibility\", \"change\", \"debate\", \"sense\", \"method\", \"theory\",\n",
    "            \"finding\", \"question\", \"idea\", \"concept\", \"opinion\", \"ideas\", \"things\"\n",
    "        ]\n",
    "        }\n",
    "        candidates = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            ind = False\n",
    "            lemmas = list(res_test[res_test['Sent'] == s]['Lemma'])\n",
    "            for l in lemmas:\n",
    "                for don in d['dons']:\n",
    "                    try:\n",
    "                        ind = lemmas.index(don)\n",
    "                    except:\n",
    "                        continue\n",
    "            cands = [0] * len(lemmas)\n",
    "            if ind:\n",
    "                cands[ind] = list(test.Tag)[int(s)]\n",
    "            else:\n",
    "                pass\n",
    "            candidates += cands\n",
    "        res_test['Tag'] = candidates\n",
    "        next_lemma = []\n",
    "        next_next_lemma = []\n",
    "        next_next_next_lemma = []\n",
    "        next_next_next_next_lemma = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            lemmas = res_test[res_test['Sent'] == s]['Lemma']\n",
    "            next_lemma += get_right_context(lemmas, 1)\n",
    "            next_next_lemma += get_right_context(lemmas, 2)\n",
    "            next_next_next_lemma += get_right_context(lemmas, 3)\n",
    "            next_next_next_next_lemma += get_right_context(lemmas, 4)\n",
    "        res_test['next_lemma'] = next_lemma\n",
    "        res_test['next_next_lemma'] = next_next_lemma\n",
    "        res_test['next_next_next_lemma'] = next_next_next_lemma\n",
    "        res_test['next_next_next_next_lemma'] = next_next_next_next_lemma\n",
    "\n",
    "        next_pos = []\n",
    "        next_next_pos = []\n",
    "        next_next_next_pos = []\n",
    "        next_next_next_next_pos = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            poss = res_test[res_test['Sent'] == s]['UPosTag']\n",
    "            next_pos += get_right_context(poss, 1)\n",
    "            next_next_pos += get_right_context(poss, 2)\n",
    "            next_next_next_pos += get_right_context(poss, 3)\n",
    "            next_next_next_next_pos += get_right_context(poss, 4)\n",
    "        res_test['next_pos'] = next_pos\n",
    "        res_test['next_next_pos'] = next_next_pos\n",
    "        res_test['next_next_next_pos'] = next_next_next_pos\n",
    "        res_test['next_next_next_next_pos'] = next_next_next_next_pos\n",
    "\n",
    "        next_rel = []\n",
    "        next_next_rel = []\n",
    "        next_next_next_rel = []\n",
    "        next_next_next_next_rel = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            rels = res_test[res_test['Sent'] == s]['DepRel']\n",
    "            next_rel += get_right_context(rels, 1)\n",
    "            next_next_rel += get_right_context(rels, 2)\n",
    "            next_next_next_rel += get_right_context(rels, 3)\n",
    "            next_next_next_next_rel += get_right_context(rels, 4)\n",
    "        res_test['next_rel'] = next_rel\n",
    "        res_test['next_next_rel'] = next_next_rel\n",
    "        res_test['next_next_next_rel'] = next_next_next_rel\n",
    "        res_test['next_next_next_next_rel'] = next_next_next_next_rel\n",
    "        pre_lemma = []\n",
    "        pre_pre_lemma = []\n",
    "        pre_pre_pre_lemma = []\n",
    "        pre_pre_pre_pre_lemma = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            lemmas = res_test[res_test['Sent'] == s]['Lemma']\n",
    "            pre_lemma += get_left_context(lemmas, 1)\n",
    "            pre_pre_lemma += get_left_context(lemmas, 2)\n",
    "            pre_pre_pre_lemma += get_left_context(lemmas, 3)\n",
    "            pre_pre_pre_pre_lemma += get_left_context(lemmas, 4)\n",
    "        res_test['pre_lemma'] = pre_lemma\n",
    "        res_test['pre_pre_lemma'] = pre_pre_lemma\n",
    "        res_test['pre_pre_pre_lemma'] = pre_pre_pre_lemma\n",
    "        res_test['pre_pre_pre_pre_lemma'] = pre_pre_pre_pre_lemma\n",
    "\n",
    "        pre_pos = []\n",
    "        pre_pre_pos = []\n",
    "        pre_pre_pre_pos = []\n",
    "        pre_pre_pre_pre_pos = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            poss = res_test[res_test['Sent'] == s]['UPosTag']\n",
    "            pre_pos += get_left_context(poss, 1)\n",
    "            pre_pre_pos += get_left_context(poss, 2)\n",
    "            pre_pre_pre_pos += get_left_context(poss, 3)\n",
    "            pre_pre_pre_pre_pos += get_left_context(poss, 4)\n",
    "        res_test['pre_pos'] = pre_pos\n",
    "        res_test['pre_pre_pos'] = pre_pre_pos\n",
    "        res_test['pre_pre_pre_pos'] = pre_pre_pre_pos\n",
    "        res_test['pre_pre_pre_pre_pos'] = pre_pre_pre_pre_pos\n",
    "\n",
    "        pre_rel = []\n",
    "        pre_pre_rel = []\n",
    "        pre_pre_pre_rel = []\n",
    "        pre_pre_pre_pre_rel = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            rels = res_test[res_test['Sent'] == s]['DepRel']\n",
    "            pre_rel += get_left_context(rels, 1)\n",
    "            pre_pre_rel += get_left_context(rels, 2)\n",
    "            pre_pre_pre_rel += get_left_context(rels, 3)\n",
    "            pre_pre_pre_pre_rel += get_left_context(rels, 4)\n",
    "        res_test['pre_rel'] = pre_rel\n",
    "        res_test['pre_pre_rel'] = pre_pre_rel\n",
    "        res_test['pre_pre_pre_rel'] = pre_pre_pre_rel\n",
    "        res_test['pre_pre_pre_pre_rel'] = pre_pre_pre_pre_rel\n",
    "        that = []\n",
    "        for s in set(res_test['Sent']):\n",
    "            lemmas = list(res_test[res_test['Sent'] == s]['Lemma'])\n",
    "            if 'that' in lemmas:\n",
    "                that += [1] * len(lemmas)\n",
    "            else:\n",
    "                that += [0] * len(lemmas)\n",
    "        res_test['that'] = that\n",
    "        df_test = res_test[~(res_test['Tag'] == 0)]\n",
    "        df_test['Tag'] = df_test['Tag'].map({'DON': 1, 'notDON': 0})\n",
    "        cols = [col for col in df_test.columns if col not in ['Tag', 'Sent']]\n",
    "        X_test = df_test[cols]\n",
    "        y_test = df_test['Tag']\n",
    "        X_train, X_test = build_dataset(\n",
    "            X_train,\n",
    "            X_test,\n",
    "            cat_cols=list(X_train.columns)[:-1],\n",
    "            num_cols = ['that']\n",
    "            )\n",
    "        _X_train = X_train.toarray()\n",
    "        _X_test = X_test.toarray()\n",
    "        model = SVC(kernel=\"linear\", C=0.025, random_state=SEED).fit(_X_train, y_train)\n",
    "        preds = model.predict(_X_test)\n",
    "        return list(preds).count(1), df_test\n",
    "    except:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431a04f5d6bb4cbfa335827c9214fef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=258), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cc = []\n",
    "for p in tqdm(paths):\n",
    "    with open(p, 'r') as file:\n",
    "        text = file.read()\n",
    "        sent_text = nltk.sent_tokenize(text)\n",
    "        c, df_test = into_data_for_model(sent_text, X_train)\n",
    "        cc.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-2b2d9e8ab88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cc' is not defined"
     ]
    }
   ],
   "source": [
    "len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "None\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "None\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "None\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "0\n",
      "None\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "5\n",
      "1\n",
      "1\n",
      "None\n",
      "1\n",
      "0\n",
      "None\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "None\n",
      "1\n",
      "0\n",
      "2\n",
      "None\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "None\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "None\n",
      "None\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "None\n",
      "None\n",
      "2\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "None\n",
      "0\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "None\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "1\n",
      "None\n",
      "0\n",
      "None\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for a in cc:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv('/Users/irene/Desktop/Диплом/code/result_criteria/DONs.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Essay</th>\n",
       "      <th>Class</th>\n",
       "      <th>Type</th>\n",
       "      <th>Number of DONs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aver</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>aver</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aver</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>worst</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Essay  Class  Type  Number of DONs\n",
       "0      1   aver     1               0\n",
       "1      2   aver     1               0\n",
       "2      3   aver     1               3\n",
       "3      4  worst     2               1\n",
       "4      5  worst     1               0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = p[p['Class'] == 'best']\n",
    "worst = p[p['Class'] == 'worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Критерий: Number of DONs\n",
      "t = 2.34642\n",
      "p = 0.04189\n",
      "Статистически значимая разница по критерию 'Number of DONs'\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_ind(best['Number of DONs'],worst['Number of DONs'])\n",
    "print('Критерий:', 'Number of DONs')\n",
    "print(\"t = \" + str(round(t, 5)))\n",
    "print(\"p = \" + str(round(2*p, 5)))\n",
    "if 2*p < 0.05:\n",
    "    print(\"Статистически значимая разница по критерию '%s'\" % 'Number of DONs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
